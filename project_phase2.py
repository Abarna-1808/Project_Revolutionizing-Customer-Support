# -*- coding: utf-8 -*-
"""project-phase2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iJETOBVyOWcD81xQYxq0v4UCAiEFk8Jw

Upload the Dataset
"""

from google.colab import files
uploaded = files.upload()

"""Load the Dataset"""

import pandas as pandas
df = pd.read_csv('medicine_and_drug_price_data(20k)_Bangladesh.csv',sep=';')

"""Data Exploration"""

df.head()

print("Shape:", df.shape)
print("Columns:", df.columns.tolist())
df.info()
df.describe()

"""Check for MIssing Values and Duplicates"""

print(df.isnull().sum())
print("Duplicate rows:",df.duplicated().sum())

"""Visualize a Few Features"""

from flask import Flask, request, jsonify
import datetime

app = Flask(__name__)

# 1. Intent Recognition
def detect_intent(user_message):
    user_message = user_message.lower()
    if "refund" in user_message:
        return "refund"
    elif "track" in user_message or "order status" in user_message:
        return "track_order"
    elif "agent" in user_message or "talk to someone" in user_message:
        return "handoff"
    else:
        return "unknown"

# 2. Automated Responses
def generate_response(intent):
    responses = {
        "refund": "Sure! Please provide your order ID for refund processing.",
        "track_order": "I'd be happy to help. Please share your tracking number.",
        "handoff": "I'll connect you with a live agent. Please wait a moment.",
        "unknown": "Sorry, I didn't understand that. Can I connect you to a support agent?"
    }
    return responses.get(intent, responses["unknown"])

# 3. Log Interactions
def log_interaction(message, intent):
    with open("logs.txt", "a") as file:
        timestamp = datetime.datetime.now()
        file.write(f"{timestamp} | Message: '{message}' | Intent: '{intent}'\n")

# 4. API Endpoint
@app.route("/chat", methods=["POST"])
def chat():
    user_input = request.json.get("message", "")
    intent = detect_intent(user_input)
    response = generate_response(intent)
    log_interaction(user_input, intent)
    return jsonify({"response": response, "intent": intent})

if __name__ == "__main__":
    app.run(debug=True)

"""Identify Target and Features"""

# Define industry keywords and chatbot features
industries = {
    "ecommerce": ["refund handling", "order tracking", "product inquiries"],
    "telecom": ["plan info", "billing support", "technical issue detection"],
    "banking": ["account queries", "fraud alerts", "transaction history"],
    "healthcare": ["appointment booking", "symptom checker", "prescription info"],
    "software_saas": ["bug reporting", "license management", "feature guidance"]
}

# Simulated input from user
def get_user_business_type():
    print("Welcome! Let's find chatbot features tailored to your business.")
    print("Choose your business domain: ecommerce, telecom, banking, healthcare, software_saas")
    return input("Enter your business type: ").strip().lower()

# Match user input to features
def identify_target_and_features(business_type):
    if business_type in industries:
        print(f"\n‚úÖ Identified Target Industry: {business_type.capitalize()}")
        print("üîß Recommended Chatbot Features:")
        for feature in industries[business_type]:
            print(f" - {feature}")
    else:
        print("\n‚ùå Unknown business type. Please try one of the listed domains.")

# Run the program
if __name__ == "__main__":
    user_input = get_user_business_type()
    identify_target_and_features(user_input)

"""Convert Categorical Columns to Numerical"""

# Identify categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns
print("Categorical Columns:", categorical_cols.tolist())

"""One-Hot Encoding"""

df_encoded = pd.get_dummies(df, drop_first=True)

"""Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler
import pandas as pd

# Example dataset (e.g., customer support data)
data = {
    'response_time_minutes': [5, 15, 30, 60, 120],
    'satisfaction_score': [3, 4, 2, 5, 1]
}

df = pd.DataFrame(data)
print("Original Data:\n", df)

# Min-Max Scaling
min_max_scaler = MinMaxScaler()
min_max_scaled = min_max_scaler.fit_transform(df)
df_min_max = pd.DataFrame(min_max_scaled, columns=df.columns)
print("\nMin-Max Scaled Data:\n", df_min_max)

# Standardization (Z-score Scaling)
standard_scaler = StandardScaler()
standard_scaled = standard_scaler.fit_transform(df)
df_standard = pd.DataFrame(standard_scaled, columns=df.columns)
print("\nStandardized Data:\n", df_standard)

"""Train-Test Split"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Sample customer support data
data = {
    'response_time_minutes': [5, 15, 30, 60, 120, 45, 10, 25],
    'satisfaction_score': [3, 4, 2, 5, 1, 4, 3, 2],
    'issue_resolved': [1, 1, 0, 1, 0, 1, 1, 0]  # Target variable
}

# Load data into a DataFrame
df = pd.DataFrame(data)

# Define features (X) and target (y)
X = df[['response_time_minutes', 'satisfaction_score']]
y = df['issue_resolved']

# Perform train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the results
print("Training Features:\n", X_train)
print("\nTraining Labels:\n", y_train)
print("\nTesting Features:\n", X_test)
print("\nTesting Labels:\n", y_test)

"""Model Building"""

# Train model
model = LinearRegression()
model.fit(X_train, y_train)
# Predict
y_pred = model.predict(X_test)

"""Evaluation"""

print("MSE:", mean_squared_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))

"""Make Predictions from New Input"""

import pandas as pd
from sklearn.linear_model import LogisticRegression

# Sample training data
data = {
    'response_time_minutes': [5, 15, 30, 60, 120, 45, 10, 25],
    'satisfaction_score': [3, 4, 2, 5, 1, 4, 3, 2],
    'issue_resolved': [1, 1, 0, 1, 0, 1, 1, 0]
}

df = pd.DataFrame(data)

# Train the model
X = df[['response_time_minutes', 'satisfaction_score']]
y = df['issue_resolved']
model = LogisticRegression()
model.fit(X, y)

# --- New Input Data ---
# Example: A customer had a 20-minute response time and gave a satisfaction score of 3
new_data = pd.DataFrame({
    'response_time_minutes': [20],
    'satisfaction_score': [3]
})

# Make prediction
prediction = model.predict(new_data)
print("Prediction (1 = Resolved, 0 = Not Resolved):", prediction[0])

"""Convert to DataFrame and Encode"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Sample raw customer support data (including a categorical feature)
raw_data = {
    'customer_id': [101, 102, 103, 104],
    'issue_type': ['billing', 'technical', 'general', 'billing'],  # Categorical
    'response_time_minutes': [15, 45, 30, 10],
    'satisfaction_score': [4, 2, 3, 5],
    'issue_resolved': [1, 0, 1, 1]
}

# Convert to DataFrame
df = pd.DataFrame(raw_data)
print("Original Data:\n", df)

# Encode 'issue_type' using Label Encoding
label_encoder = LabelEncoder()
df['issue_type_encoded'] = label_encoder.fit_transform(df['issue_type'])

# Drop original categorical column if needed
df = df.drop('issue_type', axis=1)

print("\nData After Encoding:\n", df)

"""Predict the Final Grade"""

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Sample data (e.g., support case quality based on input factors)
data = {
    'response_time_minutes': [5, 10, 20, 30, 40, 50, 60, 70],
    'issue_complexity': [1, 2, 3, 4, 5, 4, 3, 2],  # Assume scale 1 (simple) to 5 (complex)
    'agent_experience_years': [1, 1, 2, 2, 3, 4, 4, 5],
    'final_grade': [80, 78, 75, 70, 65, 68, 72, 74]  # Final customer support score
}

# Convert to DataFrame
df = pd.DataFrame(data)

# Features and target
X = df[['response_time_minutes', 'issue_complexity', 'agent_experience_years']]
y = df['final_grade']

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate the model
print("Predicted Final Grades:", y_pred)
print("Actual Final Grades:", y_test.values)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))

"""Deployment-Building an Interactive App"""

!pip install gradio

"""Create a Prediction Function"""

import pandas as pd
from sklearn.linear_model import LinearRegression

# Sample training data
data = {
    'response_time_minutes': [5, 10, 20, 30, 40, 50, 60, 70],
    'issue_complexity': [1, 2, 3, 4, 5, 4, 3, 2],
    'agent_experience_years': [1, 1, 2, 2, 3, 4, 4, 5],
    'final_grade': [80, 78, 75, 70, 65, 68, 72, 74]
}

# Convert to DataFrame
df = pd.DataFrame(data)

# Features and target
X = df[['response_time_minutes', 'issue_complexity', 'agent_experience_years']]
y = df['final_grade']

# Train model
model = LinearRegression()
model.fit(X, y)

# ---- üîÆ Prediction Function ----
def predict_final_grade(response_time, issue_complexity, agent_experience):
    input_data = pd.DataFrame({
        'response_time_minutes': [response_time],
        'issue_complexity': [issue_complexity],
        'agent_experience_years': [agent_experience]
    })
    prediction = model.predict(input_data)
    return round(prediction[0], 2)

# ---- ‚úÖ Example Usage ----
grade = predict_final_grade(response_time=25, issue_complexity=3, agent_experience=2)
print("Predicted Final Grade:", grade)

"""Create the Gradio Interface"""

import pandas as pd
from sklearn.linear_model import LinearRegression
import gradio as gr

# Sample training data
data = {
    'response_time_minutes': [5, 10, 20, 30, 40, 50, 60, 70],
    'issue_complexity': [1, 2, 3, 4, 5, 4, 3, 2],
    'agent_experience_years': [1, 1, 2, 2, 3, 4, 4, 5],
    'final_grade': [80, 78, 75, 70, 65, 68, 72, 74]
}

# Prepare the model
df = pd.DataFrame(data)
X = df[['response_time_minutes', 'issue_complexity', 'agent_experience_years']]
y = df['final_grade']
model = LinearRegression()
model.fit(X, y)

# Prediction function
def predict_final_grade(response_time, issue_complexity, agent_experience):
    input_data = pd.DataFrame({
        'response_time_minutes': [response_time],
        'issue_complexity': [issue_complexity],
        'agent_experience_years': [agent_experience]
    })
    prediction = model.predict(input_data)
    return f"Predicted Final Grade: {round(prediction[0], 2)}"

# Gradio Interface
interface = gr.Interface(
    fn=predict_final_grade,
    inputs=[
        gr.Number(label="Response Time (minutes)"),
        gr.Slider(1, 5, step=1, label="Issue Complexity (1 = Simple, 5 = Complex)"),
        gr.Number(label="Agent Experience (years)")
    ],
    outputs="text",
    title="Customer Support Grade Predictor",
    description="Enter support metrics to predict the final support grade."
)

interface.launch()